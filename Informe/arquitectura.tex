\chapter{Arquitectura del sistema}

Si bien el objetivo principal de este trabajo es incrementar la cobertura de Quepy, deseamos también que el sistema esté compartimentado de tal forma que sus componentes puedan utilizarse individualmente para otras aplicaciones.

Trabajamos sobre dos grandes áreas: un clasificador automático entrenado utlizando aprendizaje activo sobre instancias y características, y la representación de las preguntas para maximizar los resultados del clasificador. El clasificador puede ser visto como una tarea general, y por lo tanto lo desarrollamos como una librería portable cuyos parámetros pueden ser definidos por el usuario. Sin embargo, la representación de las preguntas ya descripta es algo completamente ligado al sistema de preguntas y por ello lo diseñamos como una extensión opcional de Quepy que puede utilizar cualquier clasificador.

A continuación explicaremos el ciclo de aprendizaje activo y cada una de estos módulos.

\section{Framework para aprendizaje automático sobre instancias y características}
% Basado en DUALIST Esto sería lo que haría conjuntamente con Rodri.
% Necesitamos pensar un nombre!
\subsection{Funcionalidad}
	% Para entrenarlo con active learning
	% Para obtener métricas (con esto lo vamos a medir)

\subsection{Parámetros}
\begin{description}
	\item[Clasificador] El usuario debe definir qué clasificador de sklearn utilizar.
	\item[Características]
		% Debe ser un algo que encaje dentro de un Pipeline
	\item[Corpus]
		% Qué archivos usar
		% Corpus training - no etiquetado - comprobación
			% El no etiquetado puede tener etiquetas para testing.
		% Formato que deben tener
			% diccionario de la forma {'question': pregunta, 'target': clase}
	\item[Función de representación al usuario] El usuario debe proveer una interfáz gráfica para presentar los datos al usuario y obtener una respuesta.
\end{description}
Si bien ésta aproximación es altamente paramétrica, cabe destacar que permite gran flexibilidad con respecto a los datos ingresados. Al permitir elegir tanto características como el corpus y el clasificador, puede ser utilizado dentro de cualquier ámbito incluso no relacionado al procesamiento del lenguaje natural.
% En particular se utilizaría para iepy, y citamos la tesis de Rodri. Eso se puede?

% Descripción del ciclo usuario - reentrenamiento - EM
\subsection{Selección de instancias}
\subsection{Selección de características}
En Dualist se presentaban al usuario dos listas de posibles características ordenadas de acuerdo a la correlación que tenían con cada clase. La principal diferencia con nuestra arquitectura es que tenemos 30 clases, no sólo dos, y por lo tanto debemos cambiar la forma de interacción. Por lo tanto no sólo debemos utilizar conceptos del aprendizaje activo para la selección de instancias y características, sino sobre las clases que vamos a mostrar. Cabe destacar también que en Dualist el active learning sobre ejemplos es totalmente independiente
del active learning sobre instancias.

Formas para ordenar las clases para preguntar al oráculo.
\begin{itemize}
	\item Clases que tengan la mayor probabilidad para un feature cualquiera.
	\item Clases que tengan la mayor suma de probabilidades sobre todos sus features.
	\item La clase con mayor probabilidad.
	\item La clase con menor probabilidad.
	\item La clase con mayor cantidad de instancias anotadas.
	\item La clase con menor cantidad de instancias anotadas.
\end{itemize}

\subsubsection{Information Gain}
Un criterio ampliamente utilizado para la selección de features es Information Gain.

Definición wikipedia:
In probability theory and information theory, the Kullback–Leibler divergence[1][2][3] (also information divergence, information gain, relative entropy, or KLIC; here abbreviated as KL divergence) is a non-symmetric measure of the difference between two probability distributions P and Q.

\citet{infgain}
Information gain (IG) measures the amount of information in bits about the
class prediction, if the only information available is the presence of a feature
and the corresponding class distribution. Concretely, it measures the expected
reduction in entropy

% http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=E6944FA8AB7813F0059807940A52159D?doi=10.1.1.32.9956&rep=rep1&type=pdf



\subsection{Maximización de la esperanza}
El algoritmo de maximización de la esperanza es ampliamente utilizado para inferir parámetros desconocidos en una distribución que tiene estados latentes. Para esto, utiliza estimadores de máxima verosimilitud, y para clasificación el estado latente al que nos referimos es la misma clase. A grandes rasgos, el proceso funciona en dos pasos E y M, por sus siglas en inglés Expectation y Maximization.
El paso E es el que calcula el valor esperado de la verosimilitud asumiendo que la distribución actual es verdadera y no existen variables no observadas. Para realizarlo, utilizamos el clasificador en su estado actual para etiquetar probabilisticamente el conjunto de datos no etiquetados, y asumimos dichas etiquetas como correctas. Con este conjunto de nuevos datos se calcula la verosimilitud del modelo.
Recordemos que la verosimilitud es una función sobre los parámetros del modelo y un conjunto de datos que calcula la probabilidad de los valores tomados por cada variable aleatoria del modelo bajo dichos parámetros.
Si los parámetros actuales fueran correctos, entonces la verosimilitud obtenida sería la verosimilitud real del modelo, pero si no lo son provee una cota inferior. Luego, como tenemos una función sin valores no observados, el paso M maximiza la función encontrando parámetros del modelo más adecuados. De esta forma optimizamos la cota inferior encontrada.
Este paso se repite numerosas veces hasta lograr convengercia. Sin embargo tomamos ejemplo de Settles y realizamos una sola iteración, dado que argumenta que las siguientes iteraciones no aportan significativamente a la precisión del clasificador.


%http://ai.stanford.edu/~chuongdo/papers/em_tutorial.pdf

% http://stackoverflow.com/questions/11808074/what-is-an-intuitive-explanation-of-expectation-maximization-technique

% http://cs.brown.edu/courses/cs195-5/fall2009/docs/lecture_11-12.pdf

% http://cs229.stanford.edu/notes/cs229-notes8.pdf
