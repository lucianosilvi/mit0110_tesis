\section{Entorno de experimentación}

\subsection{Ejemplos seleccionados}

% Descripción de los corpus.
	% Etiquetado
		% Las semillas son muy importantes. Deberían ser elegidas al azar?
		% La muestra debería ser representativa de la población? Aproximadamente un 10% de las preguntas son reconocidas por quepy, deberíamos incluir esto en el set de entrenamiento?
	% No etiquetado
	% Testing
		% Las que reconoce quepy?
		% 500 preguntas está bien?
Distribución actual del corpus:
Quepy questions 115
	Recognized 58
	Unrecognized 57
Other questions 6658
	Labeled 607
	Unlabeled 6051

Test corpus 250
Training corpus 165
Unlabeled corpus 6358

\subsection{Experimentos realizados}

% Automáticos sin usuarios
% Con usuarios


\subsubsection{Métricas utilizadas}
\begin{description}
    \item[Precisión] Mediremos cuántas preguntas del corpus de testing fueron etiquetadas correctamente por el clasificador. (accuracy)
    \item[Precisión en preguntas reconocidas] Debido a la gran cantidad de preguntas no etiquetadas que no comparten semántica con las preguntas originales, mediremos cuántas preguntas del corpus que no corresponden a la clase ``Otra'' son correctamente clasificadas por el sistema.
    \item[Curva de aprendizaje] Definimos la curva de aprendizaje como la presición del clasificador en función de la cantidad de ejemplos o características etiquetados necesarios.
    \item Factor kappa  -- Puede ser complejo
    \item precision y recall fijando cada clase (como si fuera una clasificación binaria)
\end{description}

\subsubsection{Baseline}
Tomaremos como baseline dos métodos:
\begin{description}
    \item[Selección de instancias y características al azar]
    \item[Bootstraping normal utilizando EM]  % Vale la pena hacer esto?
\end{description}


\subsubsection{Experimento 1}
\textbf{Hipótesis} El aprendizaje activo obtiene mejores resultados que un clasificador normal utilizando la misma cantidad de datos.
Realizamos este experimento tanto sobre instancias como sobre características.
Utilizamos un ciclo de bootstraping normal con EM donde en cada nueva iteración de agregan al conjunto de semillas las instancias que están más fuertemente asociadas a una clase.
% Nota bibliográfica acá sobre bootstraping normal.

Seleccionamos para agregar al nuevo conjunto de semillas las características con mayor ganancia de información asociadas a la clase más fuertemente asociada a ellas en base a coocurrencia. %cita a closing the loop

aprendizaje sobre instancias
sobre features
sobre ambos
sobre ninguno

\subsubsection{Experimento 2}
\textbf{Hipótesis} El aprendizaje activo sobre instancias y características obtiene mejores resultados que el aprendizaje activo sobre instancias o características por separado.
% Cómo lo medimos? Por tiempo? Por cantidad de datos etiquedos?
% Por cantidad de acciones que realiza un usuario?
% Probablemente termine siendo el mismo experimento que el anterior

\subsubsection{Experimento 3}
\textbf{Hipótesis} El aprendizaje supervisado sobre instancias y características obtiene mejores resultados que el aprendizaje supervisado sobre instancias, aún si las características son pocas.


\subsubsection{Experimento 4}
\textbf{Hipótesis} ??.

La idea es ver qué método de selección de features es mejor:\\

Puede ser trabajo futuro



\textbf{Resultados}\\

\begin{tabular}{||p{4cm} | l | l||}
\hline
 & Clase con probabilidad alta & Clase con probabilidad baja \\
\hline
Característica con probabilidad alta & medicion & medicion \\
\hline
Característica con probabilidad baja & medicion & medicion \\
\hline
\end{tabular}
\hfill
\begin{tabular}{||p{4cm} | l | l||}
\hline
 & Clase con probabilidad alta & Clase con probabilidad baja \\
\hline
Característica con IG alta & medicion & medicion \\
\hline
Característica con IG baja & medicion & medicion \\
\hline

\end{tabular}



\subsubsection{Experimento 5}
\textbf{Hipótesis} Seleccionar features para etiquetar que tengan alta confiabilidad/correlación, y luego de superado un cierto límite pasar a los que tiene baja confiabilidad/correlación permite al clasificador eliminar el ruido no introducido por la baja cantidad de ejemplos y al mismo tiempo expandir la cobertura.
Dejar para mas adelante


Experimento Entrenamiento supervisado con y sin etiquetado de  features
Validacion del etiquetado de features



Experimento 6
Information gain sobre todo el corpus o solo el etiquetado.
IG sobre el corpus anotado + frecuencia en no anotado vs IG sobre todo el corpus anotado y no anotado.


Experimento 7
Coocurrencia de features con otros features. (Información mutua)
Un feature se rankea mas alto si coocurre con features que se rankean alto. Tomando como base la frecuencia.
